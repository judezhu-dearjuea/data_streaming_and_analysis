{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a048210",
   "metadata": {},
   "source": [
    "# Project 3: Understanding User Behavior\n",
    "**Project Team: Jude Wentian Zhu, Rohit Barkshi, Rathin Bector**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b11cf",
   "metadata": {},
   "source": [
    "## Description of Project Files\n",
    "\n",
    "\n",
    "<span style=\"color:red\">**Need to fill in**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e1592",
   "metadata": {},
   "source": [
    "## Project Goal\n",
    "\n",
    "<span style=\"color:red\">**Need to fill in**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ce6bc",
   "metadata": {},
   "source": [
    "## Summary of Data Pipeline\n",
    "\n",
    "<span style=\"color:red\">**Need to fill in**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0dc452",
   "metadata": {},
   "source": [
    "## Data Pipeline Steps\n",
    "\n",
    "### Step 1: Spin up Docker-Compose and Link Pypark to Jupyter Notebook\n",
    "\n",
    "1. Spin up the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e471d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network \"project_3_default\" with the default driver\n",
      "Creating project_3_presto_1 ... \n",
      "Creating project_3_redis_1  ... \n",
      "Creating project_3_cloudera_1 ... \n",
      "Creating project_3_zookeeper_1 ... \n",
      "Creating project_3_mids_1      ... \n",
      "\u001b[3Bting project_3_cloudera_1  ... \u001b[32mdone\u001b[0m\u001b[3A\u001b[2KCreating project_3_spark_1     ... \n",
      "\u001b[3BCreating project_3_kafka_1     ... mdone\u001b[0m\u001b[3A\u001b[2K\n",
      "\u001b[1Bting project_3_kafka_1     ... \u001b[32mdone\u001b[0m\u001b[2A\u001b[2K\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6ef0c",
   "metadata": {},
   "source": [
    "2. Exec a bash shell in the spark container on teminal.\n",
    "```console\n",
    "docker-compose exec spark bash\n",
    "```\n",
    "\n",
    "\n",
    "3. Create a symbolic link from the spark directory to /w205 :\n",
    "```console\n",
    "ln -s /w205 w205\n",
    "```\n",
    "\n",
    "\n",
    "4. Exit the container\n",
    "```console\n",
    "exit\n",
    "```\n",
    "\n",
    "\n",
    "5. Check out Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c180a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxrwxrwt   - mapred mapred              0 2016-04-06 02:26 /tmp/hadoop-yarn\n",
      "drwx-wx-wx   - hive   supergroup          0 2021-08-05 04:36 /tmp/hive\n",
      "drwxrwxrwt   - mapred hadoop              0 2016-04-06 02:28 /tmp/logs\n"
     ]
    }
   ],
   "source": [
    "!docker-compose exec cloudera hadoop fs -ls /tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285bb7a",
   "metadata": {},
   "source": [
    "### Step 2: Launch Kafka and Flask\n",
    "\n",
    "1. Create a kafka topic called events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b88de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic events.\n"
     ]
    }
   ],
   "source": [
    "!docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd6fe0",
   "metadata": {},
   "source": [
    "2. Install dependencies for flask app on mids container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2b8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/w205/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/w205/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting redis\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K    100% |################################| 81kB 6.1MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "Successfully installed redis-3.5.3\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 21.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mThe directory '/w205/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/w205/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting numpy==1.14.6\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/5b/1077ec0ebfa06f42057e8315bc8e05f5978b6fd0f582879f35f4d62ff124/numpy-1.14.6-cp27-cp27mu-manylinux1_x86_64.whl (13.8MB)\n",
      "\u001b[K    100% |################################| 13.8MB 90kB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.14.6\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 21.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!docker-compose exec mids pip install redis\n",
    "!docker-compose exec mids pip install numpy==1.14.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5d43c",
   "metadata": {},
   "source": [
    "3. Run flask app on teminal\n",
    "```console\n",
    "docker-compose exec mids env FLASK_APP=/w205/project_3/game_api.py flask run --host 0.0.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2341c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!bash data_generator.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07887db1",
   "metadata": {},
   "source": [
    "5. read events from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fc613b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: docker-compose: not found\n"
     ]
    }
   ],
   "source": [
    "!docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning -e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f1b19",
   "metadata": {},
   "source": [
    "### Step 3: Data Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2f697d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10cfa392",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#defin schema\n",
    "def player_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- username: string (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "        StructField(\"username\", StringType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "    ])\n",
    "def purchase_weapon_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- username: string (nullable = true)\n",
    "    |-- weapon: string (nullable = true)\n",
    "    |-- wallet_before:integer  (nullable = true)\n",
    "    |-- wallet_after:integer  (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "        StructField(\"username\", StringType(), True),\n",
    "        StructField(\"weapon\", StringType(), True),\n",
    "        StructField(\"wallet_before\", IntegerType(), True),\n",
    "        StructField(\"wallet_after\", IntegerType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "def purchase_shield_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- username: string (nullable = true)\n",
    "    |-- wallet_before:integer  (nullable = true)\n",
    "    |-- wallet_after:integer  (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "        StructField(\"username\", StringType(), True),\n",
    "        StructField(\"wallet_before\", IntegerType(), True),\n",
    "        StructField(\"wallet_after\", IntegerType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "def dig_for_gold_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- username: string (nullable = true)\n",
    "    |-- gold_found: integer (nullable = true)\n",
    "    |-- wallet_before:integer  (nullable = true)\n",
    "    |-- wallet_after:integer  (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "        StructField(\"username\", StringType(), True),\n",
    "        StructField(\"gold_found\", IntegerType(), True),\n",
    "        StructField(\"wallet_before\", IntegerType(), True),\n",
    "        StructField(\"wallet_after\", IntegerType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "def successful_attack_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- attacker: string (nullable = true)\n",
    "    |-- defender: string (nullable = true)\n",
    "    |-- weapon_used: string (nullable = true)\n",
    "    |-- defender_has_shield: boolean (nullable = true)\n",
    "    |-- defender_health_before:integer  (nullable = true)\n",
    "    |-- defender_health_after:integer  (nullable = true)\n",
    "    |-- defender_killed: boolean (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "        StructField(\"attacker\", StringType(), True),\n",
    "        StructField(\"defender\", StringType(), True),\n",
    "        StructField(\"weapon_used\", StringType(), True),\n",
    "        StructField(\"defender_has_shield\", BooleanType(), True),\n",
    "        StructField(\"defender_health_before\", IntegerType(), True),\n",
    "        StructField(\"defender_health_after\", IntegerType(), True),\n",
    "        StructField(\"defender_killed\", BooleanType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "def failed_attack_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- attacker: string (nullable = true)\n",
    "    |-- defender: string (nullable = true)\n",
    "    |-- weapon_used: string (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "        StructField(\"attacker\", StringType(), True),\n",
    "        StructField(\"defender\", StringType(), True),\n",
    "        StructField(\"weapon_used\", StringType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5780152",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#define functions\n",
    "@udf('boolean')\n",
    "def is_player(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'initialize player':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "@udf('boolean')\n",
    "def is_purchase_weapon(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    # m = re.match('purchase',event['event_type'])\n",
    "    if event['event_type'] == 'purchase_weapon':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "@udf('boolean')\n",
    "def is_purchase_shield(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_shield':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "@udf('boolean')\n",
    "def is_dig_for_gold(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'dig_for_gold':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "@udf('boolean')\n",
    "def is_purchase_shield(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_shield':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "@udf('boolean')\n",
    "def is_successful_attack(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'successful_attack':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "@udf('boolean')\n",
    "def is_failed_attack(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'failed_attack':\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637384dd",
   "metadata": {},
   "source": [
    "Start reading events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e94ea58c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ExtractEventsJob\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "raw_events = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"events\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00f0e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract initial_player events\n",
    "player = raw_events \\\n",
    "    .filter(is_player(raw_events.value.cast('string'))) \\\n",
    "    .select(raw_events.value.cast('string').alias('raw_event'),\n",
    "            raw_events.timestamp.cast('string'),\n",
    "            from_json(raw_events.value.cast('string'),\n",
    "                      player_event_schema()).alias('json')) \\\n",
    "    .select('raw_event', 'timestamp', 'json.*')\n",
    "    \n",
    "sink_player = player \\\n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\",\"/tmp/player\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint_plyer\") \\\n",
    "    .start()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#extract purachase_weapon events\n",
    "purchase_weapon = raw_events \\\n",
    "    .filter(is_purchase_weapon(raw_events.value.cast('string'))) \\\n",
    "    .select(raw_events.value.cast('string').alias('raw_event'),\n",
    "            raw_events.timestamp.cast('string'),\n",
    "            from_json(raw_events.value.cast('string'),\n",
    "                      purchase_weapon_event_schema()).alias('json')) \\\n",
    "    .select('raw_event', 'timestamp', 'json.*')\n",
    "    \n",
    "sink_purchase_weapon = purchase_weapon \\\n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\",\"/tmp/purchase_weapon\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint_purchase_weapon\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca1c5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_player.stop()\n",
    "sink_purchase_weapon.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a317922c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_df = spark.read.parquet('/tmp/player')\n",
    "player_df.registerTempTable('player')\n",
    "\n",
    "query = 'select * from player'\n",
    "\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035de74",
   "metadata": {},
   "source": [
    "### Step 3: Use Spark to Batch Analysis"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
